# (OLD) MNIST - KlasickÃ½ pÅ™Ã­stup

TradiÄnÃ­ implementace "ML Hello World" s hotovÃ½m MNIST datasetem. Tento skript demonstruje klasickÃ½ zpÅ¯sob prÃ¡ce s ML - staÅ¾enÃ­ hotovÃ½ch dat a rychlÃ© natrÃ©novÃ¡nÃ­ modelu.

## ğŸ“œ Historie MNIST

**MNIST** (Modified National Institute of Standards and Technology database) vytvoÅ™il **Yann LeCun** a kolektiv v roce **1998**.

### PÅ¯vodnÃ­ ÃºÄel

- Benchmark pro testovÃ¡nÃ­ algoritmÅ¯ rozpoznÃ¡vÃ¡nÃ­ ruÄnÄ› psanÃ½ch ÄÃ­slic
- PrvnÃ­ ÃºspÄ›Å¡nÃ© nasazenÃ­ CNN architektury (**LeNet-5**)
- StandardizovanÃ½ dataset pro porovnÃ¡nÃ­ ML modelÅ¯

### Co MNIST obsahuje

- **60,000** trÃ©novacÃ­ch obrÃ¡zkÅ¯
- **10,000** testovacÃ­ch obrÃ¡zkÅ¯
- Velikost: **28Ã—28 pixelÅ¯**
- FormÃ¡t: **ÄŒernÃ© pÃ­smo na bÃ­lÃ©m pozadÃ­**
- Zdroj: AmerickÃ© poÅ¡tovnÃ­ formulÃ¡Å™e a studentskÃ© pÃ­semky

### ProÄ "OLD"?

V modernÃ­ ML komunitÄ› je MNIST povaÅ¾ovÃ¡n za **pÅ™etrÃ©novanÃ½ benchmark**:

- âœ… SkvÄ›lÃ½ pro vÃ½uku zÃ¡kladÅ¯
- âŒ PÅ™Ã­liÅ¡ jednoduchÃ½ - modely dosahujÃ­ 99.8% accuracy
- âŒ NerealistickÃ½ - reÃ¡lnÃ½ svÄ›t je sloÅ¾itÄ›jÅ¡Ã­
- ğŸ”„ ModernÄ›jÅ¡Ã­ alternativy: Fashion-MNIST, EMNIST, CIFAR-10

## ğŸ†š SrovnÃ¡nÃ­: OLD vs. DIE-MNIST

| Aspekt | (OLD) MNIST | DIE-MNIST |
|--------|-------------|-------------|
| **Data** | HotovÃ¡ ke staÅ¾enÃ­ | VlastnÃ­ sbÄ›r/generovÃ¡nÃ­ |
| **Velikost datasetu** | 60k train / 10k test | Dle potÅ™eby |
| **Pipeline** | `datasets.MNIST()` | CelÃ½ workflow od nuly |
| **Kontrola** | Å½Ã¡dnÃ¡ (black box) | PlnÃ¡ kontrola nad procesem |
| **UÄenÃ­** | PouÅ¾itÃ­ API | End-to-end ML pipeline |
| **CÃ­l** | RychlÃ½ prototyp | PorozumÄ›nÃ­ celÃ©mu procesu |

## ğŸš€ SpuÅ¡tÄ›nÃ­

```bash
cd (OLD)MNIST
python mnist.py
```

**PrvnÃ­ spuÅ¡tÄ›nÃ­:**

- Automaticky stÃ¡hne ~10MB MNIST data do `./data/`
- NatrÃ©nuje model (~5 minut CPU / ~1 minuta GPU)
- UloÅ¾Ã­ model do `./model/mnist_model.pt`

**DalÅ¡Ã­ spuÅ¡tÄ›nÃ­:**

- Data uÅ¾ jsou staÅ¾enÃ¡, trÃ©nink zaÄne okamÅ¾itÄ›

## ğŸ” Vizualizace dat a modelu

### ProhlÃ­Å¾enÃ­ datasetu

```bash
python show_data.py
```

ZobrazÃ­ interaktivnÃ­ okno s nÃ¡hodnÃ½mi vzorky z MNIST datasetu (6 vzorkÅ¯ z kaÅ¾dÃ© ÄÃ­slice) vÄetnÄ› statistik o rozdÄ›lenÃ­ tÅ™Ã­d.

### Vizualizace natrÃ©novanÃ©ho modelu

```bash
python show_model.py
```

Po natrÃ©novÃ¡nÃ­ modelu (spuÅ¡tÄ›nÃ­m `mnist.py`) mÅ¯Å¾ete vizualizovat:

- **Architekturu** - textovÃ½ summary s poÄtem parametrÅ¯
- **KonvoluÄnÃ­ filtry** - nauÄenÃ© vÃ¡hy 1. a 2. vrstvy jako obrÃ¡zky
- **Feature maps** - co model "vidÃ­" pÅ™i zpracovÃ¡nÃ­ ukÃ¡zkovÃ© ÄÃ­slice

Skript automaticky zkontroluje existenci modelu a v pÅ™Ã­padÄ› potÅ™eby navede ke spuÅ¡tÄ›nÃ­ trÃ©ninku.

### âš ï¸ ProÄ jsou nÄ›kterÃ© filtry "mrtvÃ©"?

PÅ™i vizualizaci feature maps uvidÃ­te, Å¾e ÄÃ¡st filtrÅ¯ je oznaÄena jako "Dead filter". To je **zÃ¡mÄ›rnÃ¡ demonstrace problÃ©mu starÃ½ch architektur**.

**Dying ReLU problÃ©m:**

- Tento model **nepouÅ¾Ã­vÃ¡ BatchNorm** (jako starÃ© CNN z roku 1998)
- ReLU aktivace mÅ¯Å¾e "zabÃ­t" neurony, kterÃ© dostÃ¡vajÃ­ vÅ¾dy negativnÃ­ vstupy
- VÃ½sledek: **40-80% filtrÅ¯ je neaktivnÃ­ch** (produkujÃ­ jen nuly)

**ProÄ model pÅ™esto funguje?**

- MNIST je **velmi jednoduchÃ½** dataset
- ZbylÃ½ch 20-60% filtrÅ¯ staÄÃ­ na 96-98% accuracy
- Na sloÅ¾itÄ›jÅ¡Ã­ch datech by model selhal

**ModernÃ­ Å™eÅ¡enÃ­:**

- DIE-MNIST v tomto projektu pouÅ¾Ã­vÃ¡ **BatchNorm2d** za kaÅ¾dou Conv vrstvou
- BatchNorm normalizuje aktivace â†’ sniÅ¾uje dying ReLU na <20%
- VÃ½sledek: **efektivnÄ›jÅ¡Ã­ model** s lepÅ¡Ã­ accuracy

To je dÅ¯vod, proÄ je oznaÄenÃ­ "(OLD)" pÅ™esnÃ© - ukazuje historickÃ½ problÃ©m a jeho modernÃ­ Å™eÅ¡enÃ­.

## ğŸ“Š OÄekÃ¡vanÃ© vÃ½sledky

Po 5 epochÃ¡ch by model mÄ›l dosÃ¡hnout:

- **Test Accuracy: 98-99%**
- **Training time: ~5 minut** (CPU) / **~1 minuta** (GPU)
- **Model size: ~600k parametrÅ¯**

## ğŸ“ Co se nauÄÃ­te

SpuÅ¡tÄ›nÃ­m tohoto skriptu:

1. âœ… VidÃ­te tradiÄnÃ­ ML workflow (stÃ¡hnout â†’ trÃ©novat â†’ testovat)
2. âœ… PochopÃ­te, co MNIST je a proÄ byl dÅ¯leÅ¾itÃ½
3. âœ… ZÃ­skÃ¡te baseline benchmark (~98-99% accuracy)
4. âœ… PochopÃ­te rozdÃ­l mezi "pouÅ¾Ã­t API" vs "postavit od nuly"

## ğŸ’¡ PouÅ¾itÃ­ jako benchmark

Po natrÃ©novÃ¡nÃ­ vlastnÃ­ho modelu mÅ¯Å¾ete porovnat vÃ½sledky:

```python
# (OLD) MNIST baseline: 98-99% accuracy (60k vzorkÅ¯, 28Ã—28)
# VÃ¡Å¡ custom model: X% accuracy (Y vzorkÅ¯, rÅ¯znÃ© rozliÅ¡enÃ­)
```

**OtÃ¡zky k zamyÅ¡lenÃ­:**

- DosÃ¡hl vÃ¡Å¡ model podobnÃ© accuracy s mÃ©nÄ› daty?
- Jak ovlivÅˆuje kvalitu a mnoÅ¾stvÃ­ vlastnÃ­ch dat?
- Je vaÅ¡e vlastnÃ­ pipeline efektivnÄ›jÅ¡Ã­ neÅ¾ hotovÃ© Å™eÅ¡enÃ­?

## ğŸ“š Reference

- **Original paper:** LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). *Gradient-based learning applied to document recognition.*
- **Dataset:** <http://yann.lecun.com/exdb/mnist/>
- **LeNet-5 architecture:** PrvnÃ­ ÃºspÄ›Å¡nÃ¡ CNN pro rozpoznÃ¡vÃ¡nÃ­ ÄÃ­slic

## ğŸ¯ ZÃ¡vÄ›r

Tento "starÃ½" pÅ™Ã­stup je:

- âœ… RychlÃ½ - funguje za pÃ¡r minut
- âœ… JednoduchÃ½ - minimÃ¡lnÃ­ kÃ³d
- âœ… SpolehlivÃ½ - otestovanÃ© Å™eÅ¡enÃ­

Ale neposkytuje:

- âŒ PorozumÄ›nÃ­ celÃ© pipeline
- âŒ Kontrolu nad daty a procesem
- âŒ ZkuÅ¡enost s real-world ML problÃ©my

**DIE-MNIST pÅ™Ã­stup uÄÃ­:**

- âœ… Jak sbÃ­rat a pÅ™ipravovat vlastnÃ­ data
- âœ… Jak navrhovat celÃ½ ML workflow
- âœ… Jak Å™eÅ¡it problÃ©my v kaÅ¾dÃ© fÃ¡zi
- âœ… ReÃ¡lnÃ½ proces, ne jen `import dataset`

---

**"The old way works. The DIE way teaches."** ğŸ“

---

<sub>Dokumentace vygenerovÃ¡na AI asistentem Claude Code (Anthropic) â€“ Å™Ã­jen 2025</sub>
