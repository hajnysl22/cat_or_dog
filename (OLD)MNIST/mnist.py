"""
(OLD) MNIST - Klasick√Ω p≈ô√≠stup

Tradiƒçn√≠ "ML Hello World" s hotov√Ωm MNIST datasetem.
Tento skript demonstruje klasick√Ω workflow: sta≈æen√≠ hotov√Ωch dat,
tr√©nink modelu a testov√°n√≠ - v≈°e v jednom souboru.

Klasick√Ω MNIST workflow:
1. Sta≈æen√≠ hotov√©ho datasetu (60k train, 10k test)
2. Vytvo≈ôen√≠ jednoduch√©ho modelu
3. Tr√©nink
4. Testov√°n√≠

Spu≈°tƒõn√≠:
    python mnist.py

Prvn√≠ spu≈°tƒõn√≠ automaticky st√°hne ~10MB MNIST data do ./data/
Model se automaticky ulo≈æ√≠ do ./model/
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from pathlib import Path

# ============================================================================
# MODEL - Jednoduch√° CNN
# ============================================================================

class SimpleMNIST(nn.Module):
    """Velmi jednoduch√° konvoluƒçn√≠ s√≠≈• pro MNIST (28√ó28 obr√°zky)."""

    def __init__(self):
        super(SimpleMNIST, self).__init__()
        # Konvoluƒçn√≠ vrstvy
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # 28x28 -> 28x28
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # 28x28 -> 28x28
        self.pool = nn.MaxPool2d(2, 2)                           # 28x28 -> 14x14 -> 7x7

        # Plnƒõ propojen√© vrstvy
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, 10)

        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        # Konvoluƒçn√≠ ƒç√°st
        x = self.relu(self.conv1(x))
        x = self.pool(x)              # 28x28 -> 14x14
        x = self.relu(self.conv2(x))
        x = self.pool(x)              # 14x14 -> 7x7

        # Flatten
        x = x.view(-1, 64 * 7 * 7)

        # Plnƒõ propojen√° ƒç√°st
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)

        return x


# ============================================================================
# HLAVN√ç PROGRAM - spust√≠ se pouze p≈ôi p≈ô√≠m√©m spu≈°tƒõn√≠ skriptu
# ============================================================================

if __name__ == "__main__":

    # ========================================================================
    # P≈ò√çPRAVA SLO≈ΩEK
    # ========================================================================

    # Vytvo≈ôen√≠ slo≈æek pro data a model (pokud neexistuj√≠)
    Path("./data").mkdir(exist_ok=True)
    Path("./model").mkdir(exist_ok=True)

    # ========================================================================
    # KONFIGURACE
    # ========================================================================

    BATCH_SIZE = 64
    EPOCHS = 5
    LEARNING_RATE = 0.01
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    print("=" * 60)
    print("(OLD) MNIST - Klasick√Ω p≈ô√≠stup s hotov√Ωmi daty")
    print("=" * 60)
    print(f"Pou≈æ√≠v√°m za≈ô√≠zen√≠: {DEVICE}")


    # ========================================================================
    # DATA - Sta≈æen√≠ a naƒçten√≠ MNIST
    # ========================================================================

    print("\nStahuji MNIST dataset...")
    print("(Prvn√≠ spu≈°tƒõn√≠ st√°hne ~10MB dat)")

    # Transformace: p≈ôevod na tensor a normalizace
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))  # MNIST mean a std
    ])

    # Sta≈æen√≠ tr√©novac√≠ sady
    train_dataset = datasets.MNIST(
        root='./data/',
        train=True,
        download=True,
        transform=transform
    )

    # Sta≈æen√≠ testovac√≠ sady
    test_dataset = datasets.MNIST(
        root='./data/',
        train=False,
        download=True,
        transform=transform
    )

    # DataLoadery pro d√°vkov√© zpracov√°n√≠
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

    print(f"Tr√©novac√≠ vzorky: {len(train_dataset)} (60,000 hotov√Ωch vzork≈Ø)")
    print(f"Testovac√≠ vzorky: {len(test_dataset)} (10,000 hotov√Ωch vzork≈Ø)")


    # ========================================================================
    # INICIALIZACE
    # ========================================================================

    model = SimpleMNIST().to(DEVICE)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    print(f"\nModel vytvo≈ôen: {sum(p.numel() for p in model.parameters())} parametr≈Ø")


    # ========================================================================
    # TR√âNINK
    # ========================================================================

    print(f"\nZaƒç√≠n√°m tr√©nink na {EPOCHS} epoch...")

    for epoch in range(EPOCHS):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for batch_idx, (data, target) in enumerate(train_loader):
            # P≈ôesun dat na GPU/CPU
            data, target = data.to(DEVICE), target.to(DEVICE)

            # Forward pass
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)

            # Backward pass
            loss.backward()
            optimizer.step()

            # Statistiky
            running_loss += loss.item()
            _, predicted = torch.max(output.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()

            # Progress ka≈æd√Ωch 100 batches
            if (batch_idx + 1) % 100 == 0:
                print(f"  Epoch [{epoch+1}/{EPOCHS}], "
                      f"Batch [{batch_idx+1}/{len(train_loader)}], "
                      f"Loss: {loss.item():.4f}")

        # Pr≈Ømƒõrn√© metriky za epochu
        epoch_loss = running_loss / len(train_loader)
        epoch_acc = 100 * correct / total
        print(f"Epoch [{epoch+1}/{EPOCHS}] dokonƒçena - "
              f"Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%")


    # ========================================================================
    # TESTOV√ÅN√ç
    # ========================================================================

    print("\nTestuji model na testovac√≠ sadƒõ...")

    model.eval()
    correct = 0
    total = 0

    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(DEVICE), target.to(DEVICE)
            output = model(data)
            _, predicted = torch.max(output.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()

    test_accuracy = 100 * correct / total
    print(f"\n{'='*60}")
    print(f"V√ùSLEDEK: Test Accuracy: {test_accuracy:.2f}%")
    print(f"{'='*60}")

    # Typick√° oƒçek√°van√° accuracy pro tento jednoduch√Ω model: 98-99%
    if test_accuracy > 99:
        print("üèÜ V√Ωborn√Ω v√Ωsledek!")
    elif test_accuracy > 97:
        print("‚úÖ Solidn√≠ v√Ωsledek!")
    else:
        print("‚ö†Ô∏è  Model by mohl b√Ωt lep≈°√≠, zkuste v√≠ce epoch nebo jinou architekturu.")


    # ========================================================================
    # ULO≈ΩEN√ç MODELU (automatick√©)
    # ========================================================================

    print("\nUkl√°d√°m model...")
    model_path = './model/mnist_model.pt'
    torch.save(model.state_dict(), model_path)
    print(f"Model ulo≈æen do {model_path}")
    print("\nPro naƒçten√≠ pou≈æijte:")
    print("  model = SimpleMNIST()")
    print(f"  model.load_state_dict(torch.load('{model_path}'))")
    print("  model.eval()")

    print("\n" + "="*60)
    print("‚úÖ Hotovo!")
    print("")
    print("   Tento 'OLD' p≈ô√≠stup je rychl√Ω a jednoduch√Ω,")
    print("   ale nauƒç√≠ v√°s jen pou≈æ√≠vat hotov√© n√°stroje.")
    print("")
    print("   Pro skuteƒçn√© pochopen√≠ ML procesu:")
    print("   vytvo≈ôte vlastn√≠ dataset a celou pipeline od nuly!")
    print("="*60)
